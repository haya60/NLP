{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5CTSTcV4ANH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import re\n",
        "import string\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import utils, layers, Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, TextVectorization\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# load dataset"
      ],
      "metadata": {
        "id": "1Te1OZZX5TVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_url = 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
        "\n",
        "dataset = utils.get_file(\n",
        "    origin=data_url,\n",
        "    untar=True,\n",
        "    cache_dir='.',\n",
        "    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
        "os.listdir(dataset_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4TdFD0l5SPf",
        "outputId": "b00163f7-f7c2-4aa0-e80d-94494d73a053"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "\u001b[1m84125825/84125825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['imdbEr.txt', 'test', 'train', 'imdb.vocab', 'README']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = os.path.join(dataset_dir , 'train')\n",
        "\n",
        "os.listdir(train_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIk7F5gR6aET",
        "outputId": "cf639b12-5cec-4a79-e993-474983a47c21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['urls_pos.txt',\n",
              " 'urls_neg.txt',\n",
              " 'pos',\n",
              " 'urls_unsup.txt',\n",
              " 'unsup',\n",
              " 'unsupBow.feat',\n",
              " 'labeledBow.feat',\n",
              " 'neg']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "remov = os.path.join(train_dir, 'unsup')\n",
        "shutil.rmtree(remov)"
      ],
      "metadata": {
        "id": "T-SPy92k8OhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dir)\n",
        "print(os.listdir(train_dir))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3apGznU_ODD",
        "outputId": "ce6df11e-534f-4a9a-901c-74668fa4fc26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/tmp/.keras/aclImdb/train\n",
            "['urls_pos.txt', 'urls_neg.txt', 'pos', 'urls_unsup.txt', 'unsupBow.feat', 'labeledBow.feat', 'neg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1024\n",
        "seed = 123\n",
        "\n",
        "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/train',\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed=seed)\n",
        "\n",
        "raw_val_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/train',\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ui-i9mQL9PtJ",
        "outputId": "426675c5-7228-4e33-be0a-c55ea0a6f477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for text_batch, label_batch in raw_train_ds.take(1): # takes one batch of data\n",
        "  for i in range(3):\n",
        "    print(\"Review:\", text_batch.numpy()[i])\n",
        "    print(\"Label:\", label_batch.numpy()[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TstuFsabAOTp",
        "outputId": "892c33ea-e26d-4bfa-c841-4209012e7ed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: b\"(aka: BLOOD CASTLE or SCREAM OF THE DEMON)<br /><br />*spoiler*<br /><br />This was a drive-in feature, co-billed with THE VELVET VAMPIRE. A Spanish-Italian co-production where a series of women in a village are being murdered around the same time a local count named Yanos Dalmar is seen on horseback, riding off with his 'man-eating' dog behind him.<br /><br />The townsfolk already suspect he is the one behind it all and want his castle burned down. The murders first began around the time Count Yanos' older brother, Count Igor Dalmar was horribly burned and killed in a lab accident.<br /><br />Then a woman Ivanna (Erna Schuer) that Igor hired before his death to assist him in his experiments shows up. Yanos agrees to hire her in place of his brother and together they seek the formulae for the regeneration of dead cells. Yanos wants to bring Igor's charred corpse back to life.<br /><br />But of course Igor is still alive (although horribly burned) and stalking and killing the women in the village. We see his char-broiled face appear at various points in the film, so we know he's still alive, making the whole thing seem a little bit too obvious.<br /><br />Igor meets another fiery end when he gets into a fight with Yanos over Ivanna, with the burning candles falling on to the same bed that Igor stumbles on to, meeting yet another, final char-broiled end.<br /><br />The Retromedia DVD is taken from a VHS source and looks quite grainy and bad. Other than an even scratchier trailer, no other extras are included. Although it has a nice, creepy Spanish castle and good atmospherics, I found it to be fairly boring and predictable, with no excitement or mystery, whatsoever. <br /><br />3 out of 10.\"\n",
            "Label: 0\n",
            "Review: b'Lordi was a major hype and revelation in 2007 because they won the Eurovision Song Contest with a (not-so-heavy) metal song called \"Hard Rock Hallelujah\" and appeared on stage dressed like hideous monsters. But, let\\'s face it, their victory most likely had very little to do with their great musical talents. The Eurovision contest gradually turned into one big political circus over the years and Lordi probably just won because their song finally brought a little change and \\xc2\\x96 even more importantly - because their whole act sort of ingeniously spoofed the whole annual event. The absolute last thing Lordi\\'s first (and hopefully last) horror film brings is change and ingenuity. \"Dark Floors\", based on an idea of the lead singer and starring the rest of the band in supportive roles, is a truly unimaginative and hopeless accumulation of clich\\xc3\\xa9s. The immense budget (\"Dark Floors\" supposedly is the most expensive Finnish film ever) definitely assures greatly macabre set pieces and impressive make-up art, but what\\'s the point where there\\'s no story that is worth telling? The film takes is set in a busy hospital where a bunch of people, among them a father and his young daughter with an unidentifiable illness, become trapped in the elevator during a power breakdown. When the doors open again, the floors are empty and it looks as if the hospital lies abandoned since many years already. Trying to reach the exit, the group stumbles upon several morbid and inexplicable obstacles, like eyeless corpses, screaming ghosts and Heavy Metal monsters emerging from the floors. The only three points I\\'m handing out to \"Dark Floors\" are exclusively intended for the scenery and the adequate tension building during the first half of the film. For as long as the sinister events don\\'t require an explanation, the atmosphere is quite creepy, but as soon as you realize the explanation will a) be very stupid or b) never come, the wholesome just collapses like an unstable house of cards. Lordi\\'s costumes never really were scary to begin with (except maybe to traditional Eurovision fans) and, in combination with a story more reminiscent to Asian ghost-horror, they just look downright pathetic and misfit. With all the national myths and truly unique exterior filming locations, I personally always presumed Finland \\xc2\\x96 The Land of a Thousand Lakes \\xc2\\x96 would be the ideal breeding ground for potentially horrific horror tales, but I guess that\\'s another disillusion on my account.'\n",
            "Label: 0\n",
            "Review: b'Almost too well done... \"John Carpenter\\'s Vampires\" was entertaining, a solid piece of popcorn-entertainment with a budget small enough not to be overrun by special effects. And obviously aiming on the \"From Dusk Till Dawn\"-audience. \"Vampires: Los Muertos\" tries the same starting with a rock-star Jon Bon Jovi playing one of the main characters, but does that almost too well...: I haven\\'t seen Jon Bon Jovi in any other movie, so I am not able to compare his acting in \"Vampires: Los Muertos\" to his other roles, but I was really suprised of his good performance. After the movie started he convinced me not expecting him to grab any guitar and playing \"It\\' my life\" or something, but kill vampires, showing no mercy and doing a job which has to be done. This means a lot, because a part of the audience (also me) was probably thinking: \"...just because he\\'s a rockstar...\". Of course Bon Jovi is not James Woods but to be honest: It could have been much worse, and in my opinion Bon Jovi did a very good performance. The vampiress played by Arly Jover is not the leather dressed killer-machine of a vampire-leader we met in Part 1 (or in similar way in \"Ghosts of Mars\"). Jover plays the vampire very seductive and very sexy, moving as lithe as a cat, attacking as fast as a snake and dressed in thin, light almost transparent very erotic cloth. And even the optical effects supporting her kind of movement are very well made. It really takes some beating. But the director is in some parts of the film only just avoiding turning the movie from an action-horrorfilm into a sensitive horrormovie like Murnau\\'s \"Nosferatu\". You can almost see the director\\'s temptation to create a movie with a VERY personal note and different to the original. This is the real strength of the movie and at the same time its weakest point: The audience celebrating the fun-bloodbath of the first movie is probably expecting a pure fun-bloodbath for the second time and might be a little disappointed. Make no mistake: \"Vampires:Los Muertos\" IS a fun-bloodbath but it\\'s just not ALL THE TIME this kind of movie. Just think of the massacre in the bar compared to the scene in which the vampiress tries to seduce Zoey in the ruins: the bar-massacre is what you expect from american popcorn-entertainment, the seducing-Zoey-in-the-ruins-scene is ALMOST european-like cinema (the movie is eager to tell us more about the relationship between Zoey and the vampiress, but refuses answers at the same time. Because it would had slow down the action? Showed the audience a vampiress with a human past, a now suffering creature and not only a beast which is just slaughtering anybody). And that\\'s the point to me which decides whether the movie is accepted by the audience of the original movie or not. And also: Is the \"From Dusk Till Dawn\"-audience really going to like this? I\\'m not sure about that. Nevertheless Tommy Lee Wallace did really a great job, \"Vampires:Los Muertos\" is surprisingly good. But I also think to direct a sequel of a popcorn movie Wallace is sometimes almost too creative, too expressive. Like he\\'s keeping himself from developing his talent in order to satisfy the expectations of audience. In my opinion, Wallace\\' talent fills the movie with life and is maybe sometimes sucking it out at the same time. \"Vampires: Los Muertos\" is almost too well done. (I give it 7 of 10)'\n",
            "Label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Label 0 corresponds to\", raw_train_ds.class_names[0])\n",
        "print(\"Label 1 corresponds to\", raw_train_ds.class_names[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTSsMbBiCpm9",
        "outputId": "cf36daac-1877-4102-dfd2-2dbef7e5ad29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label 0 corresponds to neg\n",
            "Label 1 corresponds to pos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# .cache() -> stores the data in memory after the first epoch, so the dataset does not need to be reloaded from disk in subsequent epochs\n",
        "# prefetch() ->  prepare the next batch of data while the current batch is being processed by the model\n",
        "# AUTOTUNE -> automatically determines the optimal buffer size for prefetching\n",
        "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = raw_val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "drOd8qqJBbbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding layer"
      ],
      "metadata": {
        "id": "Tgri2UO1EASb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = tf.keras.layers.Embedding(1000, 5) # 1000 -> how many unique words"
      ],
      "metadata": {
        "id": "kZDgbiMLECs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = embedding_layer(tf.constant([1, 2, 3]))\n",
        "result.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Prw4kMzNE4K-",
        "outputId": "d5d9054c-cf09-4b1d-8843-28188f584c5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.00329782,  0.01354257, -0.00340179, -0.04097612,  0.04126373],\n",
              "       [-0.04239122, -0.01558629,  0.04484452,  0.02874379, -0.01611396],\n",
              "       [-0.00583623,  0.02574802,  0.02937335,  0.03130514, -0.04689578]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text preprocessing"
      ],
      "metadata": {
        "id": "zxfEOoypFSyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_standardization(input_data):\n",
        "  lowercase = tf.strings.lower(input_data)\n",
        "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
        "  return tf.strings.regex_replace(stripped_html,\n",
        "                                  '[%s]' % re.escape(string.punctuation),\n",
        "                                  '')\n",
        "\n",
        "max_features = 10000\n",
        "sequence_length = 250\n",
        "\n",
        "vectorize_layer = layers.TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=max_features,\n",
        "    output_mode='int', #int\n",
        "    output_sequence_length=sequence_length\n",
        "    ) #  output_sequence_length -> Ensure all text sequences are 100 words long (pad shorter texts or truncate longer ones)."
      ],
      "metadata": {
        "id": "HDGifwK2FSA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a text-only dataset (without labels), then call adapt\n",
        "train_text = raw_train_ds.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(train_text)"
      ],
      "metadata": {
        "id": "kfVivPViIESH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create model"
      ],
      "metadata": {
        "id": "_n9uBG9HKpsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim=16 # the size of the vector space in which words will be embedded.\n",
        "\n",
        "model = Sequential([\n",
        "  vectorize_layer,\n",
        "  Embedding(max_features, embedding_dim, name=\"embedding\"),\n",
        "  GlobalAveragePooling1D(),\n",
        "  Dense(16, activation='relu'),\n",
        "  Dense(1)\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "W5J4vveVI0-y",
        "outputId": "0c03353b-b3d0-46b6-866a-5bbcaa6fcd2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ text_vectorization_1                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mTextVectorization\u001b[0m)                  │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d             │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ text_vectorization_1                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)                  │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "zwwTHaUdMliP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs)"
      ],
      "metadata": {
        "id": "fwqnnLndMo7Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}